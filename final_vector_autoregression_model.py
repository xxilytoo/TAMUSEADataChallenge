# -*- coding: utf-8 -*-
"""Final Vector AutoRegression Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1dBmvdS-9h9ukiH-wbz3SA-vw1DyIGv9O
"""

import torch
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

#read in CSV File to see if inputs are right
df = pd.read_csv("finaldata.csv")
df.head()

import pandas as pd
import matplotlib.pyplot as plt

# Assuming your data is in a CSV file named "sea_level_data.csv"
# Adjust the filename accordingly if your data is in a different format
file_path = "finaldata.csv"

# Read the CSV file into a DataFrame
data = pd.read_csv(file_path)

# Get unique location hashes
unique_hashes = data['Location Hashed'].unique()

# Plotting
plt.figure(figsize=(10, 6))
for location_hash in unique_hashes:
    location_data = data[data['Location Hashed'] == location_hash]
    plt.plot(location_data['Time'], location_data['Mean Sea Level Rise'], marker='o', linestyle='-', label=location_hash)

plt.title('Mean Sea Level Rise Over Time for Different Location Hashes')
plt.xlabel('Time')
plt.ylabel('Mean Sea Level Rise')
plt.grid(True)
plt.xticks(rotation=45)
plt.legend(title='Location Hashed', bbox_to_anchor=(1.05, 1), loc='upper left')
plt.tight_layout()
plt.show()

# Iterate over each unique location hash
for location_hash in unique_hashes:
    # Filter the data based on the location hash
    location_data = data[data['Location Hashed'] == location_hash]

    # Define the filename for the CSV file
    output_file = f"{location_hash}.csv"

    # Save the filtered data to a CSV file
    location_data.to_csv(output_file, index=False)

dm = pd.read_csv("fb3t5ddw3.csv", index_col='Time')
dm = dm.drop(columns=["Location Hashed"])
dm.head()

import numpy as np
import warnings
warnings.filterwarnings('ignore')

dm.shape

fig, axes = plt.subplots(nrows=5, ncols=1, dpi=120, figsize=(10,6))
for i, ax in enumerate(axes.flatten()):
  data = dm[dm.columns[i]]
  ax.plot(data, color='blue', linewidth=1)
  ax.set_title(dm.columns[i])
plt.tight_layout();

from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.statespace.varmax import VARMAX
from statsmodels.tsa.api import VAR
from statsmodels.tsa.stattools import grangercausalitytests, adfuller
from tqdm import tqdm_notebook
from itertools import product

#Verfies if data is stationary
#p-value <0.05 for it to be stationary
ad_fuller_result_1 = adfuller(dm['Mean Sea Level Rise'])

print('Mean Sea Level Rise')
print(f'ADF Statistic: {ad_fuller_result_1[0]}')
print(f'p-value: {ad_fuller_result_1[1]}')

print('\n---------------------\n')

ad_fuller_result_2 = adfuller(dm['MGRD'])

print('MGRD')
print(f'ADF Statistic: {ad_fuller_result_2[0]}')
print(f'p-value: {ad_fuller_result_2[1]}')

#covert MGRD to stationary
# Remove missing values from the differenced MGRD data
diff_mgrd = dm['MGRD'].diff()[1:]
diff_mgrd = diff_mgrd.dropna()

# Perform the ADF test on the differenced MGRD data
ad_fuller_result_2change = adfuller(diff_mgrd)

# Print the ADF test results
print('MGRD')
print(f'ADF Statistic: {ad_fuller_result_2change[0]}')
print(f'p-value: {ad_fuller_result_2change[1]}')

#check if MSLR is correlated with MGRD
#p-val less than 0.05 means that lag's causation should be used
print("does mslr cause mgrd")
granger_1 = grangercausalitytests(dm[['Mean Sea Level Rise','MGRD']],4)

print("does MGRD cause MSLR")
granger_2 = grangercausalitytests(dm[["MGRD","Mean Sea Level Rise"]], 5)

#should use lag of 1 for mslr and lag of 5 for mgrd
dm = dm[['Mean Sea Level Rise','MBSL', 'MGRD', 'MIBE']]
print(dm.shape)

from sklearn import model_selection as sk
train_data, test_data = sk.train_test_split(dm, train_size = 0.8, shuffle=False)
print(train_data.shape)
print(test_data.shape)

#Experimenting to find lags
traindiff = train_data.diff()[1:]
traindiff.dropna(inplace=True) #drops all NaN values
model = VAR(traindiff)

sorted_order=model.select_order(maxlags=20)
print(sorted_order.summary())

#use 13 lags as results show

final_var = VARMAX(train_data, order=(13,0), enforce_stationarity = True)
final_fitted = final_var.fit(disp=False)
print(final_fitted.summary)

forecastnum = 293
predict = final_fitted.get_prediction(start = len(train_data), end = len(train_data) + forecastnum - 1)
predictions = predict.predicted_mean
predictions.columns = ["MSLR Predicted", "MBSL Predicted", "MGRD Predicted", "MIBE Predicted"]
print(predictions)

dz = pd.read_csv("fb3t5ddw3.csv")
dz = dz[1171:]
dz = dz[["Time"]]
finalprediction = pd.concat([dz.reset_index(drop = True), predictions.reset_index(drop = True)], axis = 1)
finalprediction.set_index("Time", inplace = True)
finalprediction.head()

pd.to_datetime(dz["Time"])

testvpred = pd.concat([test_data, finalprediction], axis=1)
testvpred.plot(figsize=(20,10))

from sklearn.metrics import mean_squared_error
import math
from statistics import mean

MSLR_ulc=math.sqrt(mean_squared_error(predictions['MSLR Predicted'],test_data['Mean Sea Level Rise']))
print('Mean value of MSLR is : {}. Root Mean Squared Error is :{}'.format(mean(test_data['Mean Sea Level Rise']),MSLR_ulc))

rmse_rgnp=math.sqrt(mean_squared_error(predictions['MGRD Predicted'],test_data['MGRD']))
print('Mean value of MGRD is : {}. Root Mean Squared Error is :{}'.format(mean(test_data['MGRD']),rmse_rgnp))

test_data = test_data[["Mean Sea Level Rise"]]
finalprediction = finalprediction[["MSLR Predicted"]]
graph = pd.concat([test_data, finalprediction], axis=1)
graph.plot(figsize=(20,10))